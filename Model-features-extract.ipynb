{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a9552c-b976-4c6a-8883-84ae37bcc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llmfact import LayerOutputExtractor, FBNFeatureExtractor, GroupFBNFeatureExtractor, FBNExtractor, LLMFC\n",
    "# from llmfact.extractor import MutiLayerAnalysis\n",
    "# from llmfact.extractor import SingleLayerAnalysis\n",
    "# from llmfact.mask import MaskedGPT2ForSequenceClassification, MaskedGPT2AmplifiedForSequenceClassification, MaskedGPT2LMModel, MaskedModel\n",
    "# from transformers import GPT2Model, GPT2Config, GPT2LMHeadModel, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
    "# from transformers import GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForCausalLM\n",
    "# from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names\n",
    "from torch.utils.data import DataLoader\n",
    "# from rouge_score import rouge_scorer\n",
    "# from evaluate import load\n",
    "\n",
    "# from llmfact.utils import IoU, correlation_activation, thresholding, write_layer_txt, evaluate_iou\n",
    "# from llmfact.stat import  StatICA, StatDictionaryLearning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import FastICA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]  = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfa3428-85f8-4c37-81a2-9c75704c5e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cbcb026b7446d68b110d64abdccfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999807c06b494d10b52f077400b0228f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefe6e2e92cb4c54a37283d7ba136bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a491c0b314085893b13f31e5e24cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27418751101641d4b201fc184ed55124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a5450b7b38436c865b8dd57709000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model = AutoModel.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af84c483-c0b9-4905-9f91-3c9402ca717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralModel(\n",
       "  (embed_tokens): Embedding(32000, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x MistralDecoderLayer(\n",
       "      (self_attn): MistralAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): MistralMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  (rotary_emb): MistralRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b880cab-b677-455a-b529-895316c2e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.0',\n",
       " 'layers.1',\n",
       " 'layers.2',\n",
       " 'layers.3',\n",
       " 'layers.4',\n",
       " 'layers.5',\n",
       " 'layers.6',\n",
       " 'layers.7',\n",
       " 'layers.8',\n",
       " 'layers.9',\n",
       " 'layers.10',\n",
       " 'layers.11',\n",
       " 'layers.12',\n",
       " 'layers.13',\n",
       " 'layers.14',\n",
       " 'layers.15',\n",
       " 'layers.16',\n",
       " 'layers.17',\n",
       " 'layers.18',\n",
       " 'layers.19',\n",
       " 'layers.20',\n",
       " 'layers.21',\n",
       " 'layers.22',\n",
       " 'layers.23',\n",
       " 'layers.24',\n",
       " 'layers.25',\n",
       " 'layers.26',\n",
       " 'layers.27',\n",
       " 'layers.28',\n",
       " 'layers.29',\n",
       " 'layers.30',\n",
       " 'layers.31']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_layers = []\n",
    "for i in range(32):\n",
    "    include_layers.append(f'layers.{i}')\n",
    "include_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e50b76-b91a-4326-8374-fde0538853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names\n",
    "wiki_dataset = load_dataset(\"Self-GRIT/wikitext-2-raw-v1-preprocessed\", split='train')\n",
    "inputs_list = [tokenizer(inputs, return_tensors=\"pt\") for inputs in wiki_dataset['text'][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219031cf-c3c7-4d37-8105-0162d4264915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 5.26 s, total: 39.7 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from llmfact.decomposition.canica import CanICA\n",
    "from llmfact.utils import z_score_signals\n",
    "from llmfact import LayerOutputExtractor\n",
    "extractor = LayerOutputExtractor(model, include_layers, device=model.device)\n",
    "layer_outputs_list = [extractor.extract_layer_outputs(inputs) for inputs in inputs_list]\n",
    "# torch.save(layer_outputs_list, \"./data/llama3-8b-wikitext2-10-4096.pth\")\n",
    "# torch.save(layer_outputs_list, \"./data/llama2-7b-chat-hf-wikitext2-10-4096\")\n",
    "# torch.save(layer_outputs_list, \"./data/chatglm2-6b-wikitext2-10-4096.pth\")\n",
    "torch.save(layer_outputs_list, \"./data/mistral-7b-v0.1-wikitext2-10-4096.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b681c9f0-6fc4-4db0-8ac2-fd777a5cc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3992b15-1a48-424e-8453-eb800baa43b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cbf76-162a-4f29-99e8-550b5f621aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
